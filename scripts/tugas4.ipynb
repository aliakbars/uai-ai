{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Artificial Intelligence & Machine Learning\n",
    "\n",
    "## Tugas 4: Bayesian Networks & Natural Language Processing\n",
    "\n",
    "### Mekanisme\n",
    "\n",
    "Anda hanya diwajibkan untuk mengumpulkan file ini saja ke uploader yang disediakan di https://elearning.uai.ac.id/. Ganti nama file ini saat pengumpulan menjadi **tugas4_NIM.ipynb**.\n",
    "\n",
    "**Keterlambatan**: Pengumpulan tugas yang melebihi tenggat yang telah ditentukan tidak akan diterima. Keterlambatan akan berakibat pada nilai nol untuk tugas ini.\n",
    "\n",
    "**Kolaborasi**: Anda diperbolehkan untuk berdiskusi dengan teman Anda, tetapi dilarang keras menyalin kode maupun tulisan dari teman Anda. Kecurangan akan berakibat pada nilai nol untuk tugas ini.\n",
    "\n",
    "### Petunjuk\n",
    "\n",
    "Anda diperbolehkan (jika dirasa perlu) untuk mengimpor modul tambahan untuk tugas ini. Namun, seharusnya modul yang tersedia sudah cukup untuk memenuhi kebutuhan Anda. Untuk kode yang Anda ambil dari sumber lain, **cantumkan URL menuju referensi tersebut jika diambil dari internet**!\n",
    "\n",
    "Perhatikan poin untuk tiap soal! **Semakin kecil poinnya, berarti kode yang diperlukan untuk menjawab soal tersebut seharusnya semakin sedikit!**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "\n",
    "plt.rcParams = plt.rcParamsOrig"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Hidden Markov Model (10 poin)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Soal 1.1 (8 poin)\n",
    "\n",
    "Anda diberikan kelas Hidden Markov Model yang harus Anda lengkapi bagian-bagian di dalamnya. Dalam mengisi bagian-bagian tersebut, Anda tidak diperkenankan mengubah kerangka yang sudah diberikan.\n",
    "\n",
    "Implementasikan metode/fungsi:\n",
    "1. `gamma` (2 poin)\n",
    "2. `normalised_gamma` (2 poin)\n",
    "3. `log_probability` (2 poin)\n",
    "4. `fit` (2 poin)\n",
    "\n",
    "Untuk memudahkan, dalam implementasi di bawah ini variabel `a` adalah α dan variabel `b` adalah β."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm.notebook import trange\n",
    "\n",
    "class HMM:\n",
    "    def __init__(self, p_start, p_trans, p_emit, p_stop=None):\n",
    "        assert p_trans.shape[0] == p_emit.shape[0]\n",
    "        self.p_start = p_start\n",
    "        self.p_trans = p_trans\n",
    "        self.p_emit = p_emit\n",
    "        if p_stop is not None:\n",
    "            self.p_stop = p_stop\n",
    "        else:\n",
    "            self.p_stop = np.ones(self.p_trans.shape[0]) # mengisi dengan 1 untuk probabilitas berhenti\n",
    "    \n",
    "    def forward(self, sequence: list):\n",
    "        a = []\n",
    "        for i, x in enumerate(sequence):\n",
    "            if i == 0:\n",
    "                a.append((self.p_start * self.p_emit[x]).values)\n",
    "            else:\n",
    "                a.append(\n",
    "                    a[i-1].dot(\n",
    "                        self.p_trans.dot(np.diag(self.p_emit[x]))\n",
    "                    )\n",
    "                )\n",
    "        self.a = np.array(a)\n",
    "        return self\n",
    "    \n",
    "    def backward(self, sequence: list):\n",
    "        b = []\n",
    "        prev_x = sequence[-1]\n",
    "        for i, x in enumerate(sequence[::-1]): # membaca observasi dari belakang ke depan\n",
    "            if i == 0:\n",
    "                b.append(self.p_stop)\n",
    "            else:\n",
    "                b.append(\n",
    "                    b[i-1].dot(\n",
    "                        np.diag(self.p_emit[prev_x]).dot(\n",
    "                            self.p_trans.T\n",
    "                        )\n",
    "                    )\n",
    "                )\n",
    "            prev_x = x\n",
    "        self.b = np.array(b[::-1]) # mengembalikan urutan β\n",
    "        return self\n",
    "    \n",
    "    def forward_backward(self, sequence: list):\n",
    "        return self.forward(sequence).backward(sequence).normalised_gamma\n",
    "    \n",
    "    @property\n",
    "    def gamma(self):\n",
    "        \"\"\"γ = α * β\n",
    "        Mengembalikan nilai γ di setiap state.\n",
    "        \"\"\"\n",
    "        pass\n",
    "    \n",
    "    @property\n",
    "    def normalised_gamma(self):\n",
    "        \"\"\"Normalisasi γ agar mendapatkan probabilitas.\n",
    "        Total semua nilai dalam satu baris = 1.\n",
    "        \"\"\"\n",
    "        pass\n",
    "    \n",
    "    def log_probability(self, seq: list) -> float:\n",
    "        \"\"\"Menjalankan forward-backward agar mendapatkan nilai γ.\n",
    "        Mengembalikan nilai log dari jumlah nilai γ dari salah satu state.\n",
    "        \n",
    "        Catatan: Total nilai γ di setiap state selalu sama.\n",
    "        \"\"\"\n",
    "        pass\n",
    "\n",
    "    def fit(self, seq: list, max_iter=100):\n",
    "        \"\"\"Memperbaiki nilai p_emit berdasarkan observasi yang dilakukan.\n",
    "        Tidak mengembalikan nilai apapun.\n",
    "        \"\"\"\n",
    "        pass\n",
    "\n",
    "    def predict(self, seq):\n",
    "        return self.forward_backward(seq).argmax(axis=1)\n",
    "    \n",
    "    def predict_proba(self, seq):\n",
    "        return self.forward_backward(seq)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Contoh kasus di bawah ini diadaptasi dari [sini](https://github.com/jmschrei/pomegranate/blob/master/tutorials/B_Model_Tutorial_3_Hidden_Markov_Models.ipynb). Contoh ini adalah penggunaan HMM untuk mencari sequence DNA yang banyak mengandung nukleotida CG. Contoh kasus ini merupakan penyederhanaan dari kasus biologi yang riil dalam [DNA sequencing](https://en.wikipedia.org/wiki/DNA_sequencing).\n",
    "\n",
    "Anda dapat menggunakan kode di bawah ini untuk menguji hasil implementasi Anda. Kalau tidak ada pesan error, berarti implementasi Anda sudah benar."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sequence: CGACTACTGACTACTCGCCGACGCGACTGCCGTCTATACTGCGCATACGGC\n",
      "hmm pred: 000000000000000111111111111111100000000000000000000\n"
     ]
    }
   ],
   "source": [
    "# Kasus uji - jangan diubah!\n",
    "p_emit = pd.DataFrame({\n",
    "    's1': {'A': 0.25, 'C': 0.25, 'G': 0.25, 'T': 0.25},\n",
    "    's2': {'A': 0.10, 'C': 0.40, 'G': 0.40, 'T': 0.10}\n",
    "}).T\n",
    "p_trans = pd.DataFrame({\n",
    "    's1': {'s1': 0.89, 's2': 0.10},\n",
    "    's2': {'s1': 0.1, 's2': 0.9}\n",
    "}).T\n",
    "mdl = HMM(\n",
    "    p_start=np.array([0.5, 0.5]),\n",
    "    p_trans=p_trans,\n",
    "    p_emit=p_emit,\n",
    "    p_stop=np.array([0.01, 0.])\n",
    ")\n",
    "\n",
    "seq = list('CGACTACTGACTACTCGCCGACGCGACTGCCGTCTATACTGCGCATACGGC')\n",
    "hmm_predictions = mdl.predict(seq)\n",
    "print(\"sequence: {}\".format(''.join(seq)))\n",
    "print(\"hmm pred: {}\".format(''.join(map(str, hmm_predictions))))\n",
    "\n",
    "assert ''.join(map(str, hmm_predictions)) == \"000000000000000111111111111111100000000000000000000\"\n",
    "assert np.allclose(mdl.forward_backward(seq).sum(axis=1), np.ones(len(seq)))\n",
    "assert np.isclose(mdl.log_probability(seq), -76.1486)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Soal 1.2 (2 poin)\n",
    "\n",
    "Dari contoh kasus uji di atas, jelaskan maksud nilai `p_start = (0.5, 0.5)`!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Jawaban Anda di sini*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Soal 1.3.a (bonus - 2 poin)\n",
    "\n",
    "Lengkapi fungsi berikut untuk menerjemahkan state dari HMM ke karakter alfabet dan spasi."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import string\n",
    "\n",
    "def translate(states: list):\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Soal 1.3.b (bonus - 3 poin)\n",
    "\n",
    "Dengan menggunakan HMM, terjemahkan cipher text yang diberikan berikut ini. Probabilitas transisi (`p_trans`) yang dilatih dari 10000 teks berita berbahasa Indonesia sudah diberikan untuk Anda. Sebagai petunjuk, Anda dapat menggunakan uniform distribution untuk `p_start` dan `p_emit` di awal.\n",
    "\n",
    "Catatan: Hasil prediksi dari model HMM tidak akan 100% benar. 1 poin dari soal ini didapat dari perbaikan prediksi HMM ke teks asli (plain text) dari cipher text tersebut secara manual."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4d3a300894f748748e161e04706eae17",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'qali dangka inyanesia pengan ini menyahakan pemerpertan inyanesia dah dah yang mengenti belinyawan perjastan dan kain kain disemenggalakan pengan dala sersala dan dakal pemba yang sesingkah singkahnya'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cipher_text = 'cipx qidnsi xdyedlsxi yldnid xdx pldtizicid clplwylciid xdyedlsxi bim bim tidn pldnldix vlpxdyibid clcuisiid yid mixd mixd yxslmldnniwicid yldnid aiwi slcsipi yid yimip zlpve tidn slsxdnciz sxdncizdti'\n",
    "K = 27\n",
    "p_trans = pd.read_csv('https://raw.githubusercontent.com/aliakbars/uai-ai/master/datasets/p_trans.csv', index_col=0)\n",
    "\n",
    "# Kode Anda di sini"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Natural Language Processing (10 poin)\n",
    "\n",
    "Natural language processing (NLP) berkaitan cukup erat dengan Hidden Markov Model (HMM) dan Bayesian networks secara umum. Salah satu hubungannya adalah konsep language modelling. Di soal di atas, Anda sudah diberikan langsung `p_trans` untuk digunakan. Pada bagian ini, Anda diminta untuk melatih *probabilistic language models*, i.e. `p_trans`, untuk \"mengajari\" komputer/mesin untuk \"mengerti\" bahasa manusia. Artikel yang digunakan dalam tugas ini diambil dari [Leipzig Corpora Collection](https://corpora.uni-leipzig.de/en?corpusId=ind_mixed_2013)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       [kami, memang, nggak, punya, alat, pelacak, na...\n",
       "1       [selain, ayu, ting, ting, di, dalam, mobil, ro...\n",
       "2       [schweinsteiger, dan, sami, khedira, pada, pia...\n",
       "3       [sky, rink, juga, menyediakan, kelas, ice, hok...\n",
       "4       [medan, antara, news, asosiasi, pengusaha, ind...\n",
       "                              ...                        \n",
       "1995    [surat, kabar, tersebut, mengatakan, dia, teng...\n",
       "1996    [rumah, gadang, nantinya, bisa, digunakan, unt...\n",
       "1997    [kesalahan, yang, dilakukan, oleh, kepala, dae...\n",
       "1998    [konferensi, pembebasan, palestina, dilangsung...\n",
       "1999    [dengan, langkah, ini, pasar, modal, diharapka...\n",
       "Name: 1, Length: 2000, dtype: object"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "articles = pd.read_csv(\n",
    "    'https://raw.githubusercontent.com/aliakbars/uai-ai/master/datasets/ind_news_2012_10K-sentences.txt',\n",
    "    sep='\\t', header=None, quoting=3\n",
    ")[1][:2000]\n",
    "articles = articles.str.lower().apply(lambda x: re.findall(\"[a-z]+\", x))\n",
    "articles"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Soal 2.1 (2 poin)\n",
    "\n",
    "Salah satu konsep dasar dalam *language model* adalah n-gram. Secara matematis, persoalan ini diformulasikan sebagai:\n",
    "\n",
    "$$\n",
    "p(w_1,w_2,...,w_{t-1},w_t) \\approx \\prod_{i=1}^{t} p(w_i|w_{i-1})\n",
    "$$\n",
    "\n",
    "sehingga kita bisa memanfaatkan bigram (2-gram) untuk memperdiksi kata berikutnya jika diketahui kata sekarang. Hasil pencacahan dari kumpulan bigram itulah yang dapat dijadikan sebagai probabilitas $p(w_t|w_{t-1})$.\n",
    "\n",
    "$$\n",
    "p(w_2|w_1) = \\frac{c(w_1, w_2)}{c(w_1)}\n",
    "$$\n",
    "\n",
    "Petunjuk: Referensi tambahan bisa dilihat di [buku ini](http://web.stanford.edu/~jurafsky/slp3/3.pdf) hal. 4. Anda *boleh* memanfaatkan modul `Counter` dan `ngrams`. Namun, looping bisa menjadi solusi yang lebih sederhana untuk Anda."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "from nltk import ngrams\n",
    "\n",
    "# Kode Anda di sini"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Soal 2.2 (2 poin)\n",
    "\n",
    "Untuk menyederhanakan, ambil 5000 bigrams yang paling sering muncul. Lalu, buatlah pandas DataFrame dalam variabel `df` yang berbentuk:\n",
    "\n",
    "|    | w1      | w2      |   freq |\n",
    "|---:|:--------|:--------|-------:|\n",
    "|  0 | antara  | news    |     62 |\n",
    "|  1 | saat    | ini     |     52 |\n",
    "|  2 | salah   | satu    |     42 |\n",
    "|  3 | menurut | dia     |     41 |\n",
    "|  4 | di      | jakarta |     34 |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Kode Anda di sini"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Soal 2.3 (2 poin)\n",
    "\n",
    "Lengkapi fungsi berikut yang dapat memilih kata $w_t$ yang probabilitasnya paling besar jika diberikan $w_{t-1}$, i.e.\n",
    "\n",
    "$$\n",
    "w_t = \\arg \\max_{w_i} p(w_i|w_{t-1})\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Kode ini digunakan untuk Laplace smoothing\n",
    "dfc = (\n",
    "    df\n",
    "    .set_index(['w1','w2'])\n",
    "    .freq\n",
    "    .unstack(fill_value=0)\n",
    "    .stack()\n",
    "    .reset_index(name='freq')\n",
    ")\n",
    "dfc['freq'] += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_next_word(dfc, w):\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Soal 2.4 (2 poin)\n",
    "\n",
    "Sebagai variasi, Anda dapat mengganti kata yang dipilih untuk $w_t$ dengan memilih secara acak dari 5 kata dengan probabilitas tertinggi."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_next_random_word(dfc, w, n=5):\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Soal 2.5 (2 poin)\n",
    "\n",
    "Buatlah fungsi yang menerima input berupa `dfc` dan jumlah kata dalam kalimat yang mau dihasilkan, serta menggunakan `get_next_word()` untuk menghasilkan kata berikutnya."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_sentence(dfc, n=10):\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'a pendapat migrasi a pencari a pencegahan pendapat meminta'"
      ]
     },
     "execution_count": 192,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generate_sentence(dfc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Soal 2.6 (bonus - 5 poin)\n",
    "\n",
    "Dari fungsi `generate_sentence()` di atas, kata pertama selalu dipilih secara acak dan berakhir setelah jumlah kata sesuai parameter `n`. Modifikasi representasi bigram agar dapat menerima `<start>` dan `<end>` sebagai token untuk mengawali dan mengakhiri kalimat. Dengan demikian, panjang kalimat akan ditentukan oleh kata terakhir yang muncul dan awal kalimat dimulai dengan:\n",
    "1. kata-kata yang paling sering dipakai untuk mengawali kalimat di sebuah artikel; atau\n",
    "2. diberikan oleh pengguna."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
