{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Artificial Intelligence & Machine Learning\n",
    "\n",
    "## Tugas 3: Search & Reinforcement Learning\n",
    "\n",
    "### Mekanisme\n",
    "\n",
    "Anda hanya diwajibkan untuk mengumpulkan file ini saja ke uploader yang disediakan di https://elearning.uai.ac.id/. Ganti nama file ini saat pengumpulan menjadi **tugas3_NIM.ipynb**.\n",
    "\n",
    "**Keterlambatan**: Pengumpulan tugas yang melebihi tenggat yang telah ditentukan tidak akan diterima. Keterlambatan akan berakibat pada nilai nol untuk tugas ini.\n",
    "\n",
    "**Kolaborasi**: Anda diperbolehkan untuk berdiskusi dengan teman Anda, tetapi dilarang keras menyalin kode maupun tulisan dari teman Anda. Kecurangan akan berakibat pada nilai nol untuk tugas ini.\n",
    "\n",
    "### Petunjuk\n",
    "\n",
    "Anda diperbolehkan (jika dirasa perlu) untuk mengimpor modul tambahan untuk tugas ini. Namun, seharusnya modul yang tersedia sudah cukup untuk memenuhi kebutuhan Anda. Untuk kode yang Anda ambil dari sumber lain, **cantumkan URL menuju referensi tersebut jika diambil dari internet**!\n",
    "\n",
    "Perhatikan poin untuk tiap soal! **Semakin kecil poinnya, berarti kode yang diperlukan untuk menjawab soal tersebut seharusnya semakin sedikit!**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "\n",
    "plt.rcParams = plt.rcParamsOrig"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Dynamic Programming (5 poin)\n",
    "\n",
    "[Seorang pria di Australia pada tahun 2017 memesan 200 McNuggets](https://www.businessinsider.com.au/the-man-who-tried-to-order-200-chicken-nuggets-at-a-mcdonalds-drive-through-was-a-vegan-2017-12) melalui *drive-through* hingga diliput oleh media setempat. Asumsikan bahwa McDonald's bersedia memenuhi permintaan tersebut dan dalam menu terdapat kombinasi paket McNuggets berisi 3, 6, 10, dan 24. Buatlah program dinamis untuk menghitung berapa jumlah paket McNuggets minimum yang dapat diberikan kepada pria tersebut!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dynamic_prog_mcnuggets(total_mcnuggets: int, packs: list):\n",
    "    pass # Kode Anda di sini"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dynamic_prog_mcnuggets(200, [3, 6, 10, 24])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Search (10 poin)\n",
    "\n",
    "Diberikan peta UK sebagai berikut."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import networkx as nx\n",
    "\n",
    "locs = pd.read_csv('https://raw.githubusercontent.com/aliakbars/uai-ai/master/datasets/uk-coordinates.csv')\n",
    "heuristics = pd.read_csv('https://raw.githubusercontent.com/aliakbars/uai-ai/master/datasets/uk-heuristics.csv')\n",
    "G = nx.read_gpickle('https://github.com/aliakbars/uai-ai/raw/master/datasets/uk.pickle')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def draw_map(G, locs):\n",
    "    pos = locs.set_index('city_name').apply(\n",
    "        lambda x: (x['longitude'], x['latitude']),\n",
    "        axis=1\n",
    "    ).to_dict()\n",
    "    \n",
    "    fig, ax = plt.subplots(figsize=(7, 7))\n",
    "\n",
    "    nx.draw(\n",
    "        G, pos,\n",
    "        with_labels=True,\n",
    "        edge_color='#DDDDDD',\n",
    "        node_color='#A0CBE2',\n",
    "        node_size=300,\n",
    "        font_size=10,\n",
    "        ax=ax\n",
    "    )\n",
    "\n",
    "    labels = nx.get_edge_attributes(G, 'weight')\n",
    "    labels = {k: np.round(v).astype(int) for k, v in labels.items()}\n",
    "\n",
    "    nx.draw_networkx_edge_labels(\n",
    "        G, pos,\n",
    "        edge_labels=labels,\n",
    "        ax=ax\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "draw_map(G, locs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Soal 2.1 (2 poin)\n",
    "\n",
    "Gunakan algoritma UCS dari `networkx` untuk mencari jalan dari London ke Edinburgh."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Kode Anda di sini"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Soal 2.2 (4 poin)\n",
    "\n",
    "Gunakan algoritma A* dari `networkx` untuk mencari jalan dari London ke Edinburgh. Implementasikan fungsi heuristik berdasarkan variabel `heuristics` yang diberikan."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def heuristic(source, target):\n",
    "    pass # Kode Anda di sini\n",
    "\n",
    "# Kode Anda di sini"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Soal 2.3 (2 poin)\n",
    "\n",
    "Berapa jarak tempuh dari jalur terpendek London ke Edinburgh dari soal 2.2?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Kode Anda di sini"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Soal 2.4 (2 poin)\n",
    "\n",
    "Apakah hasil pada soal 2.1 dan 2.2 sama? Mengapa?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Jawaban Anda di sini*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Reinforcement Learning (10 poin)\n",
    "\n",
    "Game yang akan dimainkan kali ini adalah [Frozen Lake](https://gym.openai.com/envs/FrozenLake-v0/). Terjemahan bebas dari dokumentasi:\n",
    "\n",
    "> Musim dingin telah tiba. Anda dan teman Anda sedang bermain *frisbee* dan tanpa sengaja Anda melempar cakram *frisbee* ke tengah danau. Sebagian besar danau sudah beku, tetapi ada beebrapa lubang karena esnya telah mencair. Jika Anda terjatuh ke lubang, maka Anda akan tercebur ke air yang sangat dingin. Anda harus mengambil cakram tersebut dengan menyeberangi danau. Namun, es yang Anda pijak licin, sehingga Anda tidak selalu bisa berjalan ke arah yang Anda tuju. Anda diminta mencari strategi (*policy*) berupa jalan yang aman menuju ke ubin tujuan."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Peta danau:\n",
    "```\n",
    "SFFF\n",
    "FHFH\n",
    "FFFH\n",
    "HFFG\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Soal 3.1 (4 poin)\n",
    "\n",
    "Di dalam kelas yang sudah didefinisikan di bawah ini:\n",
    "1. Implementasikan SARSA untuk memperbarui nilai Q. (2 poin)\n",
    "2. Implementasikan algoritma $\\epsilon$-greedy untuk memilih aksi. Petunjuk: Manfaatkan `np.random.random()`. (2 poin)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm.notebook import trange\n",
    "import gym\n",
    "\n",
    "class Agent:\n",
    "    def __init__(self, env, algo=\"random\", eps=0.2, eta=0.1, gamma=1):\n",
    "        self.env = env\n",
    "        self.s = env.reset() # inisialisasi state\n",
    "        self.q = np.zeros((env.observation_space.n, env.action_space.n)) # inisialisasi semua nilai pada matriks Q = 0\n",
    "        self.eps = eps # probabilitas eksplorasi\n",
    "        self.eta = eta # learning rate\n",
    "        self.gamma = gamma # discount factor\n",
    "        self.algo = algo\n",
    "    \n",
    "    def update_q(self, s, a, r, s_, a_):\n",
    "        # Implementasikan SARSA pada bagian ini\n",
    "        self.q[s, a] = ... # Kode Anda di sini\n",
    "    \n",
    "    def choose_action(self, s):\n",
    "        if self.algo == \"random\":\n",
    "            return self.env.action_space.sample()\n",
    "        elif self.algo == \"sarsa\":\n",
    "            ... # Kode Anda di sini\n",
    "        else:\n",
    "            raise NotImplementedError()\n",
    "    \n",
    "    def play(self):\n",
    "        a = self.choose_action(self.s)\n",
    "        state, reward, done, _ = self.env.step(a)\n",
    "        action = self.choose_action(state) # melihat aksi selanjutnya\n",
    "        self.update_q(self.s, a, reward, state, action)\n",
    "        self.s = state # state saat ini diperbarui\n",
    "        return done, reward\n",
    "    \n",
    "    def reset(self):\n",
    "        self.s = self.env.reset()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Soal 3.2.1 (2 poin)\n",
    "\n",
    "Simulasikan permainan ini dengan algoritma random dan SARSA. Bandingkan rata-rata `utilities` yang didapatkan."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def simulate(algo, num_episodes=10000):\n",
    "    np.random.seed(101)\n",
    "\n",
    "    env = gym.make(\"FrozenLake-v0\")\n",
    "    agent = Agent(env, algo)\n",
    "    utilities = []\n",
    "\n",
    "    for i in trange(num_episodes):\n",
    "        while True:\n",
    "            done, reward = agent.play()\n",
    "\n",
    "            if done:\n",
    "                utilities.append(reward)\n",
    "                agent.reset()\n",
    "                break\n",
    "\n",
    "    env.close()\n",
    "    \n",
    "    return agent, utilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Kode Anda di sini"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Soal 3.2.2 (2 poin)\n",
    "\n",
    "Gambarkan perubahan nilai `utilities` dari algoritma random dan SARSA dengan rolling mean 100 episodes. Apa yang dapat Anda amati?\n",
    "\n",
    "Petunjuk: Cari tentang \"pandas rolling mean\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Kode Anda di sini"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Soal 3.3 (2 poin)\n",
    "\n",
    "Tampilkan optimal policy untuk setiap state dari algoritma SARSA."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Kode Anda di sini"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Game Theory (20 poin)\n",
    "\n",
    "Mainkan game [The Evolution of Trust](http://ncase.me/trust/) untuk dapat menjawab pertanyaan-pertanyaan berikut.\n",
    "1. Berapa skor yang Anda dapatkan dari permainan pertama? (1 poin)\n",
    "1. Apa strategi yang terbaik untuk melawan **Always Cooperate** dan **Grudger**? (2 poin)\n",
    "1. Dari kelima pemain yang mewakili lima strategi, dalam permainan satu turnamen dengan 10 ronde, siapa yang mendapat skor paling kecil? Berapa poinnya? Mengapa? (2 poin)\n",
    "1. Apa saja nama lain dari strategi **Copycat**? (2 poin)\n",
    "1. Pada simulasi kelima, i.e. The Evolution of Distrust, lakukan simulasi dengan ronde sebanyak dua digit terakhir NIM Anda modulo 10, e.g. $17~mod~10 = 7$ ronde. Pemain dengan strategi seperti apa yang tersisa? Berapa poin yang didapatkan? (2 poin)\n",
    "1. Apa yang dimaksud sebagai *zero-sum game* dan *non-zero-sum game*? Game jenis apa yang membuat kepercayaan (*trust*) sulit untuk berkembang? Mengapa? (4 poin)\n",
    "1. Apa yang menjadi kelemahan dari strategi **tit-for-tat**? (1 poin)\n",
    "1. Mana strategi yang lebih baik pada simulasi keenam, i.e. Making Mistakes, **Copycat** atau **Copykitten**? (3 poin)\n",
    "1. Apa kesimpulan yang dapat Anda ambil dari permainan ini? (3 poin)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Jawaban Anda di sini*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Simultaneous Game (5 poin)\n",
    "\n",
    "Diberikan *simultaneous game* dengan *payoff matrix* sebagai berikut:\n",
    "\n",
    "| A\\B           | cooperate   | defect   |\n",
    "|:--------------|:------------|:---------|\n",
    "| **cooperate** | -1/-1       | -3/0     |\n",
    "| **defect**    | 0/-3        | -2/-2    |\n",
    "\n",
    "dengan nilai di kiri adalah *payoff* untuk pemain A dan nilai di kanan adalah *payoff* untuk pemain B.\n",
    "\n",
    "1. Berapa nilai $V_A(\\pi_A, \\pi_B)$ jika $\\pi_A = [1,0]$ dan $\\pi_B = [0,1]$? (2 poin)\n",
    "1. Apa yang dimaksud sebagai Nash Equilibrium? (2 poin)\n",
    "1. Dari permainan di atas, strategi apa dari kedua pemain yang menjadi Nash Equilibrium? (1 poin)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Jawaban Anda di sini*"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
